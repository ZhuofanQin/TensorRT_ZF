{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df938b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutel has not been installed. To use Swin-MoE, please install Tutel; otherwise, just ignore this.\n"
     ]
    }
   ],
   "source": [
    "from Swin_Transformer.models.swin_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdeea925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c9232f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SwinTransformer().eval().cuda()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fd8858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('swin_tiny_patch4_window7_224.pth')\n",
    "checkpoint = checkpoint['model']\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8633b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Swin_T.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ff2102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      dim=96, input_resolution=(56, 56), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=96, window_size=(7, 7), num_heads=3\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=96, window_size=(7, 7), num_heads=3\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.009)\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(56, 56), dim=96\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=192, input_resolution=(28, 28), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=192, window_size=(7, 7), num_heads=6\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.018)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=192, window_size=(7, 7), num_heads=6\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.027)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(28, 28), dim=192\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=384, input_resolution=(14, 14), depth=6\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.036)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.045)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.055)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.064)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.073)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.082)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(14, 14), dim=384\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=768, input_resolution=(7, 7), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=768, window_size=(7, 7), num_heads=24\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=768, window_size=(7, 7), num_heads=24\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb6f996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "input_file  = \"images/bulbul.jpg\"\n",
    "with Image.open(input_file) as img:\n",
    "    img = img.resize((224,224))\n",
    "    data = np.asarray(img).astype('float32') / float(255.0)\n",
    "    data = np.moveaxis(data, 2, 0)\n",
    "    plt.imshow(img)\n",
    "input_tensor = torch.from_numpy(np.expand_dims(data, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9ae0b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average time cost: 6.965548992156982 ms\n"
     ]
    }
   ],
   "source": [
    "time_torch = []\n",
    "total_torch = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, 100):\n",
    "        start_t = time.time()\n",
    "        cuda_tensor = input_tensor.to(\"cuda\")\n",
    "        pred = model(cuda_tensor)\n",
    "        end_t = time.time()\n",
    "        time_torch.append(end_t - start_t)\n",
    "        total_torch += time_torch[i]\n",
    "print(\"average time cost:\", total_torch * 10, \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e16dba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0644f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO ONNX\n",
    "x = torch.randn((1, 3, 224, 224)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76be2f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:470: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert H == self.img_size[0] and W == self.img_size[1], \\\n",
      "/workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:251: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H * W, \"input feature has wrong size\"\n",
      "/workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
      "/workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "/workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:71: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
      "/workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
      "/workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:337: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H * W, \"input feature has wrong size\"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/onnx/symbolic_helper.py:325: UserWarning: Type cannot be inferred, which might cause exported graph to produce incorrect results.\n",
      "  warnings.warn(\"Type cannot be inferred, which might cause exported graph to produce incorrect results.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cuda:0),\n",
      "      %patch_embed.proj.weight : Float(96, 3, 4, 4, strides=[48, 16, 4, 1], requires_grad=1, device=cuda:0),\n",
      "      %patch_embed.proj.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %patch_embed.norm.weight : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %patch_embed.norm.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.0.norm1.weight : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.0.norm1.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.0.attn.qkv.bias : Float(288, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.0.attn.proj.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.0.norm2.weight : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.0.norm2.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.0.mlp.fc1.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.0.mlp.fc2.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.1.norm1.weight : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.1.norm1.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.1.attn.qkv.bias : Float(288, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.1.attn.proj.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.1.norm2.weight : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.1.norm2.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.1.mlp.fc1.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.blocks.1.mlp.fc2.bias : Float(96, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.downsample.norm.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.0.downsample.norm.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.0.norm1.weight : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.0.norm1.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.0.attn.qkv.bias : Float(576, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.0.attn.proj.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.0.norm2.weight : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.0.norm2.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.0.mlp.fc1.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.0.mlp.fc2.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.1.norm1.weight : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.1.norm1.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.1.attn.qkv.bias : Float(576, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.1.attn.proj.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.1.norm2.weight : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.1.norm2.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.1.mlp.fc1.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.blocks.1.mlp.fc2.bias : Float(192, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.downsample.norm.weight : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.1.downsample.norm.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.0.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.0.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.0.attn.qkv.bias : Float(1152, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.0.attn.proj.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.0.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.0.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.0.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.0.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.1.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.1.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.1.attn.qkv.bias : Float(1152, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.1.attn.proj.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.1.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.1.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.1.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.1.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.2.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.2.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.2.attn.qkv.bias : Float(1152, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.2.attn.proj.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.2.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.2.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.2.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.2.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.3.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.3.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.3.attn.qkv.bias : Float(1152, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.3.attn.proj.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.3.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.3.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.3.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.3.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.4.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.4.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.4.attn.qkv.bias : Float(1152, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.4.attn.proj.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.4.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.4.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.4.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.4.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.5.norm1.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.5.norm1.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.5.attn.qkv.bias : Float(1152, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.5.attn.proj.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.5.norm2.weight : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.5.norm2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.5.mlp.fc1.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.blocks.5.mlp.fc2.bias : Float(384, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.downsample.norm.weight : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.2.downsample.norm.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.0.norm1.weight : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.0.norm1.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.0.attn.qkv.bias : Float(2304, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.0.attn.proj.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.0.norm2.weight : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.0.norm2.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.0.mlp.fc1.bias : Float(3072, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.0.mlp.fc2.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.1.norm1.weight : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.1.norm1.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.1.attn.qkv.bias : Float(2304, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.1.attn.proj.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.1.norm2.weight : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.1.norm2.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.1.mlp.fc1.bias : Float(3072, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layers.3.blocks.1.mlp.fc2.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %norm.weight : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %norm.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %head.weight : Float(1000, 768, strides=[768, 1], requires_grad=1, device=cuda:0),\n",
      "      %head.bias : Float(1000, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %2498 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2505 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2510 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2514 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2515 : Float(96, 288, strides=[1, 96], requires_grad=0, device=cuda:0),\n",
      "      %2521 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2526 : Float(1, 3, 49, 49, strides=[3, 1, 147, 3], requires_grad=0, device=cuda:0),\n",
      "      %2530 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2531 : Float(96, 96, strides=[1, 96], requires_grad=0, device=cuda:0),\n",
      "      %2536 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2540 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2541 : Float(96, 384, strides=[1, 96], requires_grad=0, device=cuda:0),\n",
      "      %2542 : Float(384, 96, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2547 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2554 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2559 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2563 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2564 : Float(96, 288, strides=[1, 96], requires_grad=0, device=cuda:0),\n",
      "      %2570 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2575 : Float(1, 3, 49, 49, strides=[3, 1, 147, 3], requires_grad=0, device=cuda:0),\n",
      "      %2581 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2583 : Float(1, 64, 1, 49, 49, strides=[153664, 2401, 2401, 49, 1], requires_grad=0, device=cuda:0),\n",
      "      %2588 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2592 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2593 : Float(96, 96, strides=[1, 96], requires_grad=0, device=cuda:0),\n",
      "      %2598 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2602 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2603 : Float(96, 384, strides=[1, 96], requires_grad=0, device=cuda:0),\n",
      "      %2604 : Float(384, 96, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2609 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2613 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2614 : Float(384, 192, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2619 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2626 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2631 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2635 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2636 : Float(192, 576, strides=[1, 192], requires_grad=0, device=cuda:0),\n",
      "      %2642 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2647 : Float(1, 6, 49, 49, strides=[6, 1, 294, 6], requires_grad=0, device=cuda:0),\n",
      "      %2651 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2652 : Float(192, 192, strides=[1, 192], requires_grad=0, device=cuda:0),\n",
      "      %2657 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2661 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2662 : Float(192, 768, strides=[1, 192], requires_grad=0, device=cuda:0),\n",
      "      %2663 : Float(768, 192, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %2668 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2675 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2680 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2684 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2685 : Float(192, 576, strides=[1, 192], requires_grad=0, device=cuda:0),\n",
      "      %2691 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2696 : Float(1, 6, 49, 49, strides=[6, 1, 294, 6], requires_grad=0, device=cuda:0),\n",
      "      %2702 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2704 : Float(1, 16, 1, 49, 49, strides=[38416, 2401, 2401, 49, 1], requires_grad=0, device=cuda:0),\n",
      "      %2709 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2713 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2714 : Float(192, 192, strides=[1, 192], requires_grad=0, device=cuda:0),\n",
      "      %2719 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2723 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2724 : Float(192, 768, strides=[1, 192], requires_grad=0, device=cuda:0),\n",
      "      %2725 : Float(768, 192, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %2730 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2734 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2735 : Float(768, 384, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %2740 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2747 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2752 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2756 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2757 : Float(384, 1152, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2763 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2768 : Float(1, 12, 49, 49, strides=[12, 1, 588, 12], requires_grad=0, device=cuda:0),\n",
      "      %2772 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2773 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2778 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2782 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2783 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2784 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cuda:0),\n",
      "      %2789 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2796 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2801 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2805 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2806 : Float(384, 1152, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2812 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2817 : Float(1, 12, 49, 49, strides=[12, 1, 588, 12], requires_grad=0, device=cuda:0),\n",
      "      %2823 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2825 : Float(1, 4, 1, 49, 49, strides=[9604, 2401, 2401, 49, 1], requires_grad=0, device=cuda:0),\n",
      "      %2830 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2834 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2835 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2840 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2844 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2845 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2846 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cuda:0),\n",
      "      %2851 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2858 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2863 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2867 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2868 : Float(384, 1152, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2874 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2879 : Float(1, 12, 49, 49, strides=[12, 1, 588, 12], requires_grad=0, device=cuda:0),\n",
      "      %2883 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2884 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2889 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2893 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2894 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2895 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cuda:0),\n",
      "      %2900 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2907 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2912 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2916 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2917 : Float(384, 1152, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2923 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2928 : Float(1, 12, 49, 49, strides=[12, 1, 588, 12], requires_grad=0, device=cuda:0),\n",
      "      %2934 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2936 : Float(1, 4, 1, 49, 49, strides=[9604, 2401, 2401, 49, 1], requires_grad=0, device=cuda:0),\n",
      "      %2941 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2945 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2946 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2951 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2955 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2956 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2957 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cuda:0),\n",
      "      %2962 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2969 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2974 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2978 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2979 : Float(384, 1152, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %2985 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2990 : Float(1, 12, 49, 49, strides=[12, 1, 588, 12], requires_grad=0, device=cuda:0),\n",
      "      %2994 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %2995 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %3000 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3004 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3005 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %3006 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cuda:0),\n",
      "      %3011 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3018 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3023 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3027 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3028 : Float(384, 1152, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %3034 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3039 : Float(1, 12, 49, 49, strides=[12, 1, 588, 12], requires_grad=0, device=cuda:0),\n",
      "      %3045 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3047 : Float(1, 4, 1, 49, 49, strides=[9604, 2401, 2401, 49, 1], requires_grad=0, device=cuda:0),\n",
      "      %3052 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3056 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3057 : Float(384, 384, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %3062 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3066 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3067 : Float(384, 1536, strides=[1, 384], requires_grad=0, device=cuda:0),\n",
      "      %3068 : Float(1536, 384, strides=[1, 1536], requires_grad=0, device=cuda:0),\n",
      "      %3073 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3077 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3078 : Float(1536, 768, strides=[1, 1536], requires_grad=0, device=cuda:0),\n",
      "      %3083 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3090 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3095 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3099 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3100 : Float(768, 2304, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %3106 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3111 : Float(1, 24, 49, 49, strides=[24, 1, 1176, 24], requires_grad=0, device=cuda:0),\n",
      "      %3115 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3116 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %3121 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3125 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3126 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %3127 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cuda:0),\n",
      "      %3132 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3139 : Long(6, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3144 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3148 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3149 : Float(768, 2304, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %3155 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3160 : Float(1, 24, 49, 49, strides=[24, 1, 1176, 24], requires_grad=0, device=cuda:0),\n",
      "      %3164 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3165 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %3170 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3174 : Long(3, strides=[1], requires_grad=0, device=cpu),\n",
      "      %3175 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cuda:0),\n",
      "      %3176 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cuda:0)):\n",
      "  %191 : Float(1, 96, 56, 56, strides=[301056, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%input, %patch_embed.proj.weight, %patch_embed.proj.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %192 : Long(4, strides=[1], device=cpu) = onnx::Shape(%191)\n",
      "  %193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %194 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %195 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %196 : Long(2, strides=[1], device=cpu) = onnx::Slice(%192, %194, %195, %193)\n",
      "  %197 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %198 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%196, %197)\n",
      "  %199 : Float(1, 96, 3136, strides=[301056, 3136, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%191, %198) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:472:0\n",
      "  %200 : Float(1, 3136, 96, strides=[301056, 1, 3136], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1]](%199) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:472:0\n",
      "  %201 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%200)\n",
      "  %202 : Float(1, 3136, 96) = onnx::Sub(%200, %201)\n",
      "  %203 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Cast[to=1](%202)\n",
      "  %204 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %205 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Pow(%203, %204)\n",
      "  %206 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%205)\n",
      "  %207 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %208 : Float(1, 3136, 1, device=cpu) = onnx::Add(%206, %207)\n",
      "  %209 : Float(1, 3136, 1, strides=[3136, 1, 1], device=cpu) = onnx::Sqrt(%208)\n",
      "  %210 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Div(%202, %209)\n",
      "  %211 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Mul(%210, %patch_embed.norm.weight)\n",
      "  %212 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%211, %patch_embed.norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %215 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%212)\n",
      "  %216 : Float(1, 3136, 96) = onnx::Sub(%212, %215)\n",
      "  %217 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Cast[to=1](%216)\n",
      "  %218 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %219 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Pow(%217, %218)\n",
      "  %220 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%219)\n",
      "  %221 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %222 : Float(1, 3136, 1, device=cpu) = onnx::Add(%220, %221)\n",
      "  %223 : Float(1, 3136, 1, strides=[3136, 1, 1], device=cpu) = onnx::Sqrt(%222)\n",
      "  %224 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Div(%216, %223)\n",
      "  %225 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Mul(%224, %layers.0.blocks.0.norm1.weight)\n",
      "  %226 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%225, %layers.0.blocks.0.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %234 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%226, %2498) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %248 : Float(1, 8, 7, 8, 7, 96, strides=[301056, 37632, 5376, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%234, %2505) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %249 : Float(1, 8, 8, 7, 7, 96, strides=[301056, 37632, 4704, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%248) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %258 : Float(64, 7, 7, 96, strides=[4704, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%249, %2510) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %265 : Float(64, 49, 96, strides=[4704, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%258, %2514) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %270 : Float(64, 49, 288, strides=[14112, 288, 1], device=cpu) = onnx::MatMul(%265, %2515)\n",
      "  %271 : Float(64, 49, 288, strides=[14112, 288, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.0.blocks.0.attn.qkv.bias, %270) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %281 : Float(64, 49, 3, 3, 32, strides=[14112, 288, 96, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%271, %2521) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %282 : Float(3, 64, 3, 49, 32, strides=[96, 14112, 32, 288, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%281) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %283 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %284 : Float(64, 3, 49, 32, strides=[14112, 32, 288, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%282, %283) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %285 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %286 : Float(64, 3, 49, 32, strides=[14112, 32, 288, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%282, %285) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %287 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %288 : Float(64, 3, 49, 32, strides=[14112, 32, 288, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%282, %287) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %289 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %290 : Float(64, 3, 49, 32, strides=[4704, 32, 96, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%284, %289)\n",
      "  %291 : Float(64, 3, 32, 49, strides=[14112, 32, 1, 288], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%286) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %292 : Float(64, 3, 49, 49, strides=[7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%290, %291) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %300 : Float(64, 3, 49, 49, strides=[7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%292, %2526) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %301 : Float(64, 3, 49, 49, strides=[7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%300) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %302 : Float(64, 3, 49, 32, strides=[4704, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%301, %288) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %303 : Float(64, 49, 3, 32, strides=[4704, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%302) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %308 : Float(64, 49, 96, strides=[4704, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%303, %2530) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %310 : Float(64, 49, 96, strides=[4704, 96, 1], device=cpu) = onnx::MatMul(%308, %2531)\n",
      "  %311 : Float(64, 49, 96, strides=[4704, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.0.blocks.0.attn.proj.bias, %310) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %320 : Float(64, 7, 7, 96, strides=[4704, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%311, %2536) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %321 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  8  8  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %322 : Float(1, 8, 8, 7, 7, 96, strides=[301056, 37632, 4704, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%320, %321) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %323 : Float(1, 8, 7, 8, 7, 96, strides=[301056, 37632, 5376, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%322) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %324 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  56  56  -1 [ CPULongType{4} ]]()\n",
      "  %325 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%323, %324) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %331 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%325, %2540) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %332 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%212, %331) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %333 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%332)\n",
      "  %334 : Float(1, 3136, 96) = onnx::Sub(%332, %333)\n",
      "  %335 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Cast[to=1](%334)\n",
      "  %336 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %337 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Pow(%335, %336)\n",
      "  %338 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%337)\n",
      "  %339 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %340 : Float(1, 3136, 1, device=cpu) = onnx::Add(%338, %339)\n",
      "  %341 : Float(1, 3136, 1, strides=[3136, 1, 1], device=cpu) = onnx::Sqrt(%340)\n",
      "  %342 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Div(%334, %341)\n",
      "  %343 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Mul(%342, %layers.0.blocks.0.norm2.weight)\n",
      "  %344 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%343, %layers.0.blocks.0.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %346 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::MatMul(%344, %2541)\n",
      "  %347 : Float(1, 3136, 384, strides=[1204224, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.0.blocks.0.mlp.fc1.bias, %346) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %348 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %349 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::Div(%347, %348)\n",
      "  %350 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::Erf(%349)\n",
      "  %351 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %352 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::Add(%350, %351)\n",
      "  %353 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::Mul(%347, %352)\n",
      "  %354 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %355 : Float(1, 3136, 384, strides=[1204224, 384, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%353, %354) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %357 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::MatMul(%355, %2542)\n",
      "  %358 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.0.blocks.0.mlp.fc2.bias, %357) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %359 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%332, %358) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %362 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%359)\n",
      "  %363 : Float(1, 3136, 96) = onnx::Sub(%359, %362)\n",
      "  %364 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Cast[to=1](%363)\n",
      "  %365 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %366 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Pow(%364, %365)\n",
      "  %367 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%366)\n",
      "  %368 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %369 : Float(1, 3136, 1, device=cpu) = onnx::Add(%367, %368)\n",
      "  %370 : Float(1, 3136, 1, strides=[3136, 1, 1], device=cpu) = onnx::Sqrt(%369)\n",
      "  %371 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Div(%363, %370)\n",
      "  %372 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Mul(%371, %layers.0.blocks.1.norm1.weight)\n",
      "  %373 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%372, %layers.0.blocks.1.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %381 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%373, %2547) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %383 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %385 : Float(1, 53, 56, 96, strides=[284928, 5376, 96, 1], device=cpu) = onnx::Slice(%381, %383, %384, %382)\n",
      "  %386 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %387 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %388 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %389 : Float(1, 3, 56, 96, strides=[16128, 5376, 96, 1], device=cpu) = onnx::Slice(%381, %387, %388, %386)\n",
      "  %390 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], device=cpu) = onnx::Concat[axis=1](%385, %389)\n",
      "  %391 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %392 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %393 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %394 : Float(1, 56, 53, 96, strides=[284928, 5088, 96, 1], device=cpu) = onnx::Slice(%390, %392, %393, %391)\n",
      "  %395 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %396 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %397 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %398 : Float(1, 56, 3, 96, strides=[16128, 288, 96, 1], device=cpu) = onnx::Slice(%390, %396, %397, %395)\n",
      "  %399 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%394, %398) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:260:0\n",
      "  %413 : Float(1, 8, 7, 8, 7, 96, strides=[301056, 37632, 5376, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%399, %2554) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %414 : Float(1, 8, 8, 7, 7, 96, strides=[301056, 37632, 4704, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%413) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %423 : Float(64, 7, 7, 96, strides=[4704, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%414, %2559) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %430 : Float(64, 49, 96, strides=[4704, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%423, %2563) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %435 : Float(64, 49, 288, strides=[14112, 288, 1], device=cpu) = onnx::MatMul(%430, %2564)\n",
      "  %436 : Float(64, 49, 288, strides=[14112, 288, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.0.blocks.1.attn.qkv.bias, %435) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %446 : Float(64, 49, 3, 3, 32, strides=[14112, 288, 96, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%436, %2570) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %447 : Float(3, 64, 3, 49, 32, strides=[96, 14112, 32, 288, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%446) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %448 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %449 : Float(64, 3, 49, 32, strides=[14112, 32, 288, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%447, %448) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %450 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %451 : Float(64, 3, 49, 32, strides=[14112, 32, 288, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%447, %450) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %452 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %453 : Float(64, 3, 49, 32, strides=[14112, 32, 288, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%447, %452) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %454 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %455 : Float(64, 3, 49, 32, strides=[4704, 32, 96, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%449, %454)\n",
      "  %456 : Float(64, 3, 32, 49, strides=[14112, 32, 1, 288], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%451) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %457 : Float(64, 3, 49, 49, strides=[7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%455, %456) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %465 : Float(64, 3, 49, 49, strides=[7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%457, %2575) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %475 : Float(1, 64, 3, 49, 49, strides=[460992, 7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%465, %2581) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %478 : Float(1, 64, 3, 49, 49, strides=[460992, 7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%475, %2583) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %486 : Float(64, 3, 49, 49, strides=[7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%478, %2588) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:146:0\n",
      "  %487 : Float(64, 3, 49, 49, strides=[7203, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%486) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %488 : Float(64, 3, 49, 32, strides=[4704, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%487, %453) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %489 : Float(64, 49, 3, 32, strides=[4704, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%488) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %494 : Float(64, 49, 96, strides=[4704, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%489, %2592) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %496 : Float(64, 49, 96, strides=[4704, 96, 1], device=cpu) = onnx::MatMul(%494, %2593)\n",
      "  %497 : Float(64, 49, 96, strides=[4704, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.0.blocks.1.attn.proj.bias, %496) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %506 : Float(64, 7, 7, 96, strides=[4704, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%497, %2598) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %507 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  8  8  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %508 : Float(1, 8, 8, 7, 7, 96, strides=[301056, 37632, 4704, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%506, %507) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %509 : Float(1, 8, 7, 8, 7, 96, strides=[301056, 37632, 5376, 672, 96, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%508) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %510 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  56  56  -1 [ CPULongType{4} ]]()\n",
      "  %511 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%509, %510) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %512 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %513 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %514 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %515 : Float(1, 3, 56, 96, strides=[16128, 5376, 96, 1], device=cpu) = onnx::Slice(%511, %513, %514, %512)\n",
      "  %516 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %517 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %518 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %519 : Float(1, 53, 56, 96, strides=[284928, 5376, 96, 1], device=cpu) = onnx::Slice(%511, %517, %518, %516)\n",
      "  %520 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], device=cpu) = onnx::Concat[axis=1](%515, %519)\n",
      "  %521 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %523 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %524 : Float(1, 56, 3, 96, strides=[16128, 288, 96, 1], device=cpu) = onnx::Slice(%520, %522, %523, %521)\n",
      "  %525 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %526 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %527 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %528 : Float(1, 56, 53, 96, strides=[284928, 5088, 96, 1], device=cpu) = onnx::Slice(%520, %526, %527, %525)\n",
      "  %529 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%524, %528) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:282:0\n",
      "  %535 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%529, %2602) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %536 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%359, %535) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %537 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%536)\n",
      "  %538 : Float(1, 3136, 96) = onnx::Sub(%536, %537)\n",
      "  %539 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Cast[to=1](%538)\n",
      "  %540 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %541 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Pow(%539, %540)\n",
      "  %542 : Float(1, 3136, device=cpu) = onnx::ReduceMean[axes=[-1]](%541)\n",
      "  %543 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %544 : Float(1, 3136, 1, device=cpu) = onnx::Add(%542, %543)\n",
      "  %545 : Float(1, 3136, 1, strides=[3136, 1, 1], device=cpu) = onnx::Sqrt(%544)\n",
      "  %546 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Div(%538, %545)\n",
      "  %547 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::Mul(%546, %layers.0.blocks.1.norm2.weight)\n",
      "  %548 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%547, %layers.0.blocks.1.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %550 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::MatMul(%548, %2603)\n",
      "  %551 : Float(1, 3136, 384, strides=[1204224, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.0.blocks.1.mlp.fc1.bias, %550) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %552 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %553 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::Div(%551, %552)\n",
      "  %554 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::Erf(%553)\n",
      "  %555 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %556 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::Add(%554, %555)\n",
      "  %557 : Float(1, 3136, 384, strides=[1204224, 384, 1], device=cpu) = onnx::Mul(%551, %556)\n",
      "  %558 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %559 : Float(1, 3136, 384, strides=[1204224, 384, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%557, %558) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %561 : Float(1, 3136, 96, strides=[301056, 96, 1], device=cpu) = onnx::MatMul(%559, %2604)\n",
      "  %562 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.0.blocks.1.mlp.fc2.bias, %561) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %563 : Float(1, 3136, 96, strides=[301056, 96, 1], requires_grad=1, device=cuda:0) = onnx::Add(%536, %562) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %573 : Float(1, 56, 56, 96, strides=[301056, 5376, 96, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%563, %2609) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %574 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %575 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %576 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %577 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %578 : Float(1, 28, 56, 96, strides=[301056, 10752, 96, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%573, %575, %576, %574, %577) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:342:0\n",
      "  %579 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %580 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %581 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %582 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %583 : Float(1, 28, 28, 96, strides=[301056, 10752, 192, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%578, %580, %581, %579, %582) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:342:0\n",
      "  %584 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %586 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %588 : Float(1, 28, 56, 96, strides=[301056, 10752, 96, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%573, %585, %586, %584, %587) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:343:0\n",
      "  %589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %590 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %592 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %593 : Float(1, 28, 28, 96, strides=[301056, 10752, 192, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%588, %590, %591, %589, %592) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:343:0\n",
      "  %594 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %595 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %596 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %597 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %598 : Float(1, 28, 56, 96, strides=[301056, 10752, 96, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%573, %595, %596, %594, %597) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:344:0\n",
      "  %599 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %600 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %601 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %602 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %603 : Float(1, 28, 28, 96, strides=[301056, 10752, 192, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%598, %600, %601, %599, %602) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:344:0\n",
      "  %604 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %605 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %606 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %607 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %608 : Float(1, 28, 56, 96, strides=[301056, 10752, 96, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%573, %605, %606, %604, %607) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %609 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %610 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %611 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %612 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %613 : Float(1, 28, 28, 96, strides=[301056, 10752, 192, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%608, %610, %611, %609, %612) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %614 : Float(1, 28, 28, 384, strides=[301056, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=-1](%583, %593, %603, %613) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:346:0\n",
      "  %621 : Float(1, 784, 384, strides=[301056, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%614, %2613) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:347:0\n",
      "  %622 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%621)\n",
      "  %623 : Float(1, 784, 384) = onnx::Sub(%621, %622)\n",
      "  %624 : Float(1, 784, 384, strides=[301056, 384, 1], device=cpu) = onnx::Cast[to=1](%623)\n",
      "  %625 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %626 : Float(1, 784, 384, strides=[301056, 384, 1], device=cpu) = onnx::Pow(%624, %625)\n",
      "  %627 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%626)\n",
      "  %628 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %629 : Float(1, 784, 1, device=cpu) = onnx::Add(%627, %628)\n",
      "  %630 : Float(1, 784, 1, strides=[784, 1, 1], device=cpu) = onnx::Sqrt(%629)\n",
      "  %631 : Float(1, 784, 384, strides=[301056, 384, 1], device=cpu) = onnx::Div(%623, %630)\n",
      "  %632 : Float(1, 784, 384, strides=[301056, 384, 1], device=cpu) = onnx::Mul(%631, %layers.0.downsample.norm.weight)\n",
      "  %633 : Float(1, 784, 384, strides=[301056, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%632, %layers.0.downsample.norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %635 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%633, %2614) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %638 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%635)\n",
      "  %639 : Float(1, 784, 192) = onnx::Sub(%635, %638)\n",
      "  %640 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Cast[to=1](%639)\n",
      "  %641 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %642 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Pow(%640, %641)\n",
      "  %643 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%642)\n",
      "  %644 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %645 : Float(1, 784, 1, device=cpu) = onnx::Add(%643, %644)\n",
      "  %646 : Float(1, 784, 1, strides=[784, 1, 1], device=cpu) = onnx::Sqrt(%645)\n",
      "  %647 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Div(%639, %646)\n",
      "  %648 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Mul(%647, %layers.1.blocks.0.norm1.weight)\n",
      "  %649 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%648, %layers.1.blocks.0.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %657 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%649, %2619) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %671 : Float(1, 4, 7, 4, 7, 192, strides=[150528, 37632, 5376, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%657, %2626) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %672 : Float(1, 4, 4, 7, 7, 192, strides=[150528, 37632, 9408, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%671) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %681 : Float(16, 7, 7, 192, strides=[9408, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%672, %2631) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %688 : Float(16, 49, 192, strides=[9408, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%681, %2635) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %693 : Float(16, 49, 576, strides=[28224, 576, 1], device=cpu) = onnx::MatMul(%688, %2636)\n",
      "  %694 : Float(16, 49, 576, strides=[28224, 576, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.1.blocks.0.attn.qkv.bias, %693) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %704 : Float(16, 49, 3, 6, 32, strides=[28224, 576, 192, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%694, %2642) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %705 : Float(3, 16, 6, 49, 32, strides=[192, 28224, 32, 576, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%704) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %706 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %707 : Float(16, 6, 49, 32, strides=[28224, 32, 576, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%705, %706) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %708 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %709 : Float(16, 6, 49, 32, strides=[28224, 32, 576, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%705, %708) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %710 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %711 : Float(16, 6, 49, 32, strides=[28224, 32, 576, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%705, %710) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %712 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %713 : Float(16, 6, 49, 32, strides=[9408, 32, 192, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%707, %712)\n",
      "  %714 : Float(16, 6, 32, 49, strides=[28224, 32, 1, 576], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%709) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %715 : Float(16, 6, 49, 49, strides=[14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%713, %714) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %723 : Float(16, 6, 49, 49, strides=[14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%715, %2647) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %724 : Float(16, 6, 49, 49, strides=[14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%723) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %725 : Float(16, 6, 49, 32, strides=[9408, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%724, %711) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %726 : Float(16, 49, 6, 32, strides=[9408, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%725) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %731 : Float(16, 49, 192, strides=[9408, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%726, %2651) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %733 : Float(16, 49, 192, strides=[9408, 192, 1], device=cpu) = onnx::MatMul(%731, %2652)\n",
      "  %734 : Float(16, 49, 192, strides=[9408, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.1.blocks.0.attn.proj.bias, %733) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %743 : Float(16, 7, 7, 192, strides=[9408, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%734, %2657) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %744 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  4  4  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %745 : Float(1, 4, 4, 7, 7, 192, strides=[150528, 37632, 9408, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%743, %744) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %746 : Float(1, 4, 7, 4, 7, 192, strides=[150528, 37632, 5376, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%745) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %747 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  28  28  -1 [ CPULongType{4} ]]()\n",
      "  %748 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%746, %747) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %754 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%748, %2661) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %755 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%635, %754) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %756 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%755)\n",
      "  %757 : Float(1, 784, 192) = onnx::Sub(%755, %756)\n",
      "  %758 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Cast[to=1](%757)\n",
      "  %759 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %760 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Pow(%758, %759)\n",
      "  %761 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%760)\n",
      "  %762 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %763 : Float(1, 784, 1, device=cpu) = onnx::Add(%761, %762)\n",
      "  %764 : Float(1, 784, 1, strides=[784, 1, 1], device=cpu) = onnx::Sqrt(%763)\n",
      "  %765 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Div(%757, %764)\n",
      "  %766 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Mul(%765, %layers.1.blocks.0.norm2.weight)\n",
      "  %767 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%766, %layers.1.blocks.0.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %769 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::MatMul(%767, %2662)\n",
      "  %770 : Float(1, 784, 768, strides=[602112, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.1.blocks.0.mlp.fc1.bias, %769) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %771 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %772 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::Div(%770, %771)\n",
      "  %773 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::Erf(%772)\n",
      "  %774 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %775 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::Add(%773, %774)\n",
      "  %776 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::Mul(%770, %775)\n",
      "  %777 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %778 : Float(1, 784, 768, strides=[602112, 768, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%776, %777) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %780 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::MatMul(%778, %2663)\n",
      "  %781 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.1.blocks.0.mlp.fc2.bias, %780) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %782 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%755, %781) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %785 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%782)\n",
      "  %786 : Float(1, 784, 192) = onnx::Sub(%782, %785)\n",
      "  %787 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Cast[to=1](%786)\n",
      "  %788 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %789 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Pow(%787, %788)\n",
      "  %790 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%789)\n",
      "  %791 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %792 : Float(1, 784, 1, device=cpu) = onnx::Add(%790, %791)\n",
      "  %793 : Float(1, 784, 1, strides=[784, 1, 1], device=cpu) = onnx::Sqrt(%792)\n",
      "  %794 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Div(%786, %793)\n",
      "  %795 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Mul(%794, %layers.1.blocks.1.norm1.weight)\n",
      "  %796 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%795, %layers.1.blocks.1.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %804 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%796, %2668) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %805 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %806 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %807 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %808 : Float(1, 25, 28, 192, strides=[134400, 5376, 192, 1], device=cpu) = onnx::Slice(%804, %806, %807, %805)\n",
      "  %809 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %810 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %812 : Float(1, 3, 28, 192, strides=[16128, 5376, 192, 1], device=cpu) = onnx::Slice(%804, %810, %811, %809)\n",
      "  %813 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], device=cpu) = onnx::Concat[axis=1](%808, %812)\n",
      "  %814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %817 : Float(1, 28, 25, 192, strides=[134400, 4800, 192, 1], device=cpu) = onnx::Slice(%813, %815, %816, %814)\n",
      "  %818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %819 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %820 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %821 : Float(1, 28, 3, 192, strides=[16128, 576, 192, 1], device=cpu) = onnx::Slice(%813, %819, %820, %818)\n",
      "  %822 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%817, %821) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:260:0\n",
      "  %836 : Float(1, 4, 7, 4, 7, 192, strides=[150528, 37632, 5376, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%822, %2675) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %837 : Float(1, 4, 4, 7, 7, 192, strides=[150528, 37632, 9408, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%836) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %846 : Float(16, 7, 7, 192, strides=[9408, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%837, %2680) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %853 : Float(16, 49, 192, strides=[9408, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%846, %2684) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %858 : Float(16, 49, 576, strides=[28224, 576, 1], device=cpu) = onnx::MatMul(%853, %2685)\n",
      "  %859 : Float(16, 49, 576, strides=[28224, 576, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.1.blocks.1.attn.qkv.bias, %858) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %869 : Float(16, 49, 3, 6, 32, strides=[28224, 576, 192, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%859, %2691) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %870 : Float(3, 16, 6, 49, 32, strides=[192, 28224, 32, 576, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%869) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %871 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %872 : Float(16, 6, 49, 32, strides=[28224, 32, 576, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%870, %871) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %873 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %874 : Float(16, 6, 49, 32, strides=[28224, 32, 576, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%870, %873) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %875 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %876 : Float(16, 6, 49, 32, strides=[28224, 32, 576, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%870, %875) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %877 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %878 : Float(16, 6, 49, 32, strides=[9408, 32, 192, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%872, %877)\n",
      "  %879 : Float(16, 6, 32, 49, strides=[28224, 32, 1, 576], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%874) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %880 : Float(16, 6, 49, 49, strides=[14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%878, %879) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %888 : Float(16, 6, 49, 49, strides=[14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%880, %2696) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %898 : Float(1, 16, 6, 49, 49, strides=[230496, 14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%888, %2702) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %901 : Float(1, 16, 6, 49, 49, strides=[230496, 14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%898, %2704) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %909 : Float(16, 6, 49, 49, strides=[14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%901, %2709) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:146:0\n",
      "  %910 : Float(16, 6, 49, 49, strides=[14406, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%909) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %911 : Float(16, 6, 49, 32, strides=[9408, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%910, %876) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %912 : Float(16, 49, 6, 32, strides=[9408, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%911) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %917 : Float(16, 49, 192, strides=[9408, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%912, %2713) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %919 : Float(16, 49, 192, strides=[9408, 192, 1], device=cpu) = onnx::MatMul(%917, %2714)\n",
      "  %920 : Float(16, 49, 192, strides=[9408, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.1.blocks.1.attn.proj.bias, %919) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %929 : Float(16, 7, 7, 192, strides=[9408, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%920, %2719) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %930 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  4  4  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %931 : Float(1, 4, 4, 7, 7, 192, strides=[150528, 37632, 9408, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%929, %930) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %932 : Float(1, 4, 7, 4, 7, 192, strides=[150528, 37632, 5376, 1344, 192, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%931) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %933 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  28  28  -1 [ CPULongType{4} ]]()\n",
      "  %934 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%932, %933) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %935 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %936 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %937 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %938 : Float(1, 3, 28, 192, strides=[16128, 5376, 192, 1], device=cpu) = onnx::Slice(%934, %936, %937, %935)\n",
      "  %939 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %940 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %941 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %942 : Float(1, 25, 28, 192, strides=[134400, 5376, 192, 1], device=cpu) = onnx::Slice(%934, %940, %941, %939)\n",
      "  %943 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], device=cpu) = onnx::Concat[axis=1](%938, %942)\n",
      "  %944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %945 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %946 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %947 : Float(1, 28, 3, 192, strides=[16128, 576, 192, 1], device=cpu) = onnx::Slice(%943, %945, %946, %944)\n",
      "  %948 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %949 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %950 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %951 : Float(1, 28, 25, 192, strides=[134400, 4800, 192, 1], device=cpu) = onnx::Slice(%943, %949, %950, %948)\n",
      "  %952 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%947, %951) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:282:0\n",
      "  %958 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%952, %2723) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %959 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%782, %958) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %960 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%959)\n",
      "  %961 : Float(1, 784, 192) = onnx::Sub(%959, %960)\n",
      "  %962 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Cast[to=1](%961)\n",
      "  %963 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %964 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Pow(%962, %963)\n",
      "  %965 : Float(1, 784, device=cpu) = onnx::ReduceMean[axes=[-1]](%964)\n",
      "  %966 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %967 : Float(1, 784, 1, device=cpu) = onnx::Add(%965, %966)\n",
      "  %968 : Float(1, 784, 1, strides=[784, 1, 1], device=cpu) = onnx::Sqrt(%967)\n",
      "  %969 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Div(%961, %968)\n",
      "  %970 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::Mul(%969, %layers.1.blocks.1.norm2.weight)\n",
      "  %971 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%970, %layers.1.blocks.1.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %973 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::MatMul(%971, %2724)\n",
      "  %974 : Float(1, 784, 768, strides=[602112, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.1.blocks.1.mlp.fc1.bias, %973) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %975 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %976 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::Div(%974, %975)\n",
      "  %977 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::Erf(%976)\n",
      "  %978 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %979 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::Add(%977, %978)\n",
      "  %980 : Float(1, 784, 768, strides=[602112, 768, 1], device=cpu) = onnx::Mul(%974, %979)\n",
      "  %981 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %982 : Float(1, 784, 768, strides=[602112, 768, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%980, %981) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %984 : Float(1, 784, 192, strides=[150528, 192, 1], device=cpu) = onnx::MatMul(%982, %2725)\n",
      "  %985 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.1.blocks.1.mlp.fc2.bias, %984) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %986 : Float(1, 784, 192, strides=[150528, 192, 1], requires_grad=1, device=cuda:0) = onnx::Add(%959, %985) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %996 : Float(1, 28, 28, 192, strides=[150528, 5376, 192, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%986, %2730) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %997 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %998 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %999 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1000 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1001 : Float(1, 14, 28, 192, strides=[150528, 10752, 192, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%996, %998, %999, %997, %1000) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:342:0\n",
      "  %1002 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1003 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1004 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1005 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1006 : Float(1, 14, 14, 192, strides=[150528, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%1001, %1003, %1004, %1002, %1005) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:342:0\n",
      "  %1007 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1008 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1009 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1010 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1011 : Float(1, 14, 28, 192, strides=[150528, 10752, 192, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%996, %1008, %1009, %1007, %1010) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:343:0\n",
      "  %1012 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1013 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1014 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1015 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1016 : Float(1, 14, 14, 192, strides=[150528, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%1011, %1013, %1014, %1012, %1015) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:343:0\n",
      "  %1017 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1018 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1019 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1020 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1021 : Float(1, 14, 28, 192, strides=[150528, 10752, 192, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%996, %1018, %1019, %1017, %1020) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:344:0\n",
      "  %1022 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1023 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1025 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1026 : Float(1, 14, 14, 192, strides=[150528, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%1021, %1023, %1024, %1022, %1025) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:344:0\n",
      "  %1027 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1028 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1029 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1030 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1031 : Float(1, 14, 28, 192, strides=[150528, 10752, 192, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%996, %1028, %1029, %1027, %1030) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %1032 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1033 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1034 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1035 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1036 : Float(1, 14, 14, 192, strides=[150528, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%1031, %1033, %1034, %1032, %1035) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %1037 : Float(1, 14, 14, 768, strides=[150528, 10752, 768, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=-1](%1006, %1016, %1026, %1036) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:346:0\n",
      "  %1044 : Float(1, 196, 768, strides=[150528, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1037, %2734) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:347:0\n",
      "  %1045 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1044)\n",
      "  %1046 : Float(1, 196, 768) = onnx::Sub(%1044, %1045)\n",
      "  %1047 : Float(1, 196, 768, strides=[150528, 768, 1], device=cpu) = onnx::Cast[to=1](%1046)\n",
      "  %1048 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1049 : Float(1, 196, 768, strides=[150528, 768, 1], device=cpu) = onnx::Pow(%1047, %1048)\n",
      "  %1050 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1049)\n",
      "  %1051 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1052 : Float(1, 196, 1, device=cpu) = onnx::Add(%1050, %1051)\n",
      "  %1053 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1052)\n",
      "  %1054 : Float(1, 196, 768, strides=[150528, 768, 1], device=cpu) = onnx::Div(%1046, %1053)\n",
      "  %1055 : Float(1, 196, 768, strides=[150528, 768, 1], device=cpu) = onnx::Mul(%1054, %layers.1.downsample.norm.weight)\n",
      "  %1056 : Float(1, 196, 768, strides=[150528, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1055, %layers.1.downsample.norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1058 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1056, %2735) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1061 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1058)\n",
      "  %1062 : Float(1, 196, 384) = onnx::Sub(%1058, %1061)\n",
      "  %1063 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1062)\n",
      "  %1064 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1065 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1063, %1064)\n",
      "  %1066 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1065)\n",
      "  %1067 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1068 : Float(1, 196, 1, device=cpu) = onnx::Add(%1066, %1067)\n",
      "  %1069 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1068)\n",
      "  %1070 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1062, %1069)\n",
      "  %1071 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1070, %layers.2.blocks.0.norm1.weight)\n",
      "  %1072 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1071, %layers.2.blocks.0.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1080 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1072, %2740) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %1094 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1080, %2747) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %1095 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1094) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1104 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1095, %2752) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1111 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1104, %2756) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %1116 : Float(4, 49, 1152, strides=[56448, 1152, 1], device=cpu) = onnx::MatMul(%1111, %2757)\n",
      "  %1117 : Float(4, 49, 1152, strides=[56448, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.0.attn.qkv.bias, %1116) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1127 : Float(4, 49, 3, 12, 32, strides=[56448, 1152, 384, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1117, %2763) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1128 : Float(3, 4, 12, 49, 32, strides=[384, 56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%1127) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1129 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1130 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1128, %1129) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1131 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1132 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1128, %1131) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1133 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1134 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1128, %1133) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1135 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %1136 : Float(4, 12, 49, 32, strides=[18816, 32, 384, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1130, %1135)\n",
      "  %1137 : Float(4, 12, 32, 49, strides=[56448, 32, 1, 1152], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%1132) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1138 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1136, %1137) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1146 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1138, %2768) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %1147 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%1146) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1148 : Float(4, 12, 49, 32, strides=[18816, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1147, %1134) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1149 : Float(4, 49, 12, 32, strides=[18816, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%1148) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1154 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1149, %2772) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1156 : Float(4, 49, 384, strides=[18816, 384, 1], device=cpu) = onnx::MatMul(%1154, %2773)\n",
      "  %1157 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.0.attn.proj.bias, %1156) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1166 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1157, %2778) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %1167 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  2  2  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %1168 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1166, %1167) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %1169 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1168) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1170 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  14  14  -1 [ CPULongType{4} ]]()\n",
      "  %1171 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1169, %1170) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1177 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1171, %2782) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %1178 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1058, %1177) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %1179 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1178)\n",
      "  %1180 : Float(1, 196, 384) = onnx::Sub(%1178, %1179)\n",
      "  %1181 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1180)\n",
      "  %1182 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1183 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1181, %1182)\n",
      "  %1184 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1183)\n",
      "  %1185 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1186 : Float(1, 196, 1, device=cpu) = onnx::Add(%1184, %1185)\n",
      "  %1187 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1186)\n",
      "  %1188 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1180, %1187)\n",
      "  %1189 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1188, %layers.2.blocks.0.norm2.weight)\n",
      "  %1190 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1189, %layers.2.blocks.0.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1192 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::MatMul(%1190, %2783)\n",
      "  %1193 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.0.mlp.fc1.bias, %1192) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1194 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %1195 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Div(%1193, %1194)\n",
      "  %1196 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Erf(%1195)\n",
      "  %1197 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1198 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Add(%1196, %1197)\n",
      "  %1199 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Mul(%1193, %1198)\n",
      "  %1200 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %1201 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1199, %1200) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1203 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::MatMul(%1201, %2784)\n",
      "  %1204 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.0.mlp.fc2.bias, %1203) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1205 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1178, %1204) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %1208 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1205)\n",
      "  %1209 : Float(1, 196, 384) = onnx::Sub(%1205, %1208)\n",
      "  %1210 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1209)\n",
      "  %1211 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1212 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1210, %1211)\n",
      "  %1213 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1212)\n",
      "  %1214 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1215 : Float(1, 196, 1, device=cpu) = onnx::Add(%1213, %1214)\n",
      "  %1216 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1215)\n",
      "  %1217 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1209, %1216)\n",
      "  %1218 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1217, %layers.2.blocks.1.norm1.weight)\n",
      "  %1219 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1218, %layers.2.blocks.1.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1227 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1219, %2789) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %1228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1229 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1231 : Float(1, 11, 14, 384, strides=[59136, 5376, 384, 1], device=cpu) = onnx::Slice(%1227, %1229, %1230, %1228)\n",
      "  %1232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1233 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1235 : Float(1, 3, 14, 384, strides=[16128, 5376, 384, 1], device=cpu) = onnx::Slice(%1227, %1233, %1234, %1232)\n",
      "  %1236 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], device=cpu) = onnx::Concat[axis=1](%1231, %1235)\n",
      "  %1237 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1239 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1240 : Float(1, 14, 11, 384, strides=[59136, 4224, 384, 1], device=cpu) = onnx::Slice(%1236, %1238, %1239, %1237)\n",
      "  %1241 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1242 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1243 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1244 : Float(1, 14, 3, 384, strides=[16128, 1152, 384, 1], device=cpu) = onnx::Slice(%1236, %1242, %1243, %1241)\n",
      "  %1245 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%1240, %1244) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:260:0\n",
      "  %1259 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1245, %2796) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %1260 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1259) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1269 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1260, %2801) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1276 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1269, %2805) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %1281 : Float(4, 49, 1152, strides=[56448, 1152, 1], device=cpu) = onnx::MatMul(%1276, %2806)\n",
      "  %1282 : Float(4, 49, 1152, strides=[56448, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.1.attn.qkv.bias, %1281) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1292 : Float(4, 49, 3, 12, 32, strides=[56448, 1152, 384, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1282, %2812) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1293 : Float(3, 4, 12, 49, 32, strides=[384, 56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%1292) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1294 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1295 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1293, %1294) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1296 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1297 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1293, %1296) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1298 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1299 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1293, %1298) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1300 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %1301 : Float(4, 12, 49, 32, strides=[18816, 32, 384, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1295, %1300)\n",
      "  %1302 : Float(4, 12, 32, 49, strides=[56448, 32, 1, 1152], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%1297) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1303 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1301, %1302) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1311 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1303, %2817) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %1321 : Float(1, 4, 12, 49, 49, strides=[115248, 28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1311, %2823) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %1324 : Float(1, 4, 12, 49, 49, strides=[115248, 28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1321, %2825) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %1332 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1324, %2830) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:146:0\n",
      "  %1333 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%1332) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1334 : Float(4, 12, 49, 32, strides=[18816, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1333, %1299) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1335 : Float(4, 49, 12, 32, strides=[18816, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%1334) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1340 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1335, %2834) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1342 : Float(4, 49, 384, strides=[18816, 384, 1], device=cpu) = onnx::MatMul(%1340, %2835)\n",
      "  %1343 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.1.attn.proj.bias, %1342) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1352 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1343, %2840) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %1353 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  2  2  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %1354 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1352, %1353) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %1355 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1354) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1356 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  14  14  -1 [ CPULongType{4} ]]()\n",
      "  %1357 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1355, %1356) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1358 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1359 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %1360 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1361 : Float(1, 3, 14, 384, strides=[16128, 5376, 384, 1], device=cpu) = onnx::Slice(%1357, %1359, %1360, %1358)\n",
      "  %1362 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1363 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1364 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %1365 : Float(1, 11, 14, 384, strides=[59136, 5376, 384, 1], device=cpu) = onnx::Slice(%1357, %1363, %1364, %1362)\n",
      "  %1366 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], device=cpu) = onnx::Concat[axis=1](%1361, %1365)\n",
      "  %1367 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1368 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %1369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1370 : Float(1, 14, 3, 384, strides=[16128, 1152, 384, 1], device=cpu) = onnx::Slice(%1366, %1368, %1369, %1367)\n",
      "  %1371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1372 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %1374 : Float(1, 14, 11, 384, strides=[59136, 4224, 384, 1], device=cpu) = onnx::Slice(%1366, %1372, %1373, %1371)\n",
      "  %1375 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%1370, %1374) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:282:0\n",
      "  %1381 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1375, %2844) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %1382 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1205, %1381) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %1383 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1382)\n",
      "  %1384 : Float(1, 196, 384) = onnx::Sub(%1382, %1383)\n",
      "  %1385 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1384)\n",
      "  %1386 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1387 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1385, %1386)\n",
      "  %1388 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1387)\n",
      "  %1389 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1390 : Float(1, 196, 1, device=cpu) = onnx::Add(%1388, %1389)\n",
      "  %1391 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1390)\n",
      "  %1392 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1384, %1391)\n",
      "  %1393 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1392, %layers.2.blocks.1.norm2.weight)\n",
      "  %1394 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1393, %layers.2.blocks.1.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1396 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::MatMul(%1394, %2845)\n",
      "  %1397 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.1.mlp.fc1.bias, %1396) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1398 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %1399 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Div(%1397, %1398)\n",
      "  %1400 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Erf(%1399)\n",
      "  %1401 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1402 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Add(%1400, %1401)\n",
      "  %1403 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Mul(%1397, %1402)\n",
      "  %1404 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %1405 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1403, %1404) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1407 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::MatMul(%1405, %2846)\n",
      "  %1408 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.1.mlp.fc2.bias, %1407) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1409 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1382, %1408) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %1412 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1409)\n",
      "  %1413 : Float(1, 196, 384) = onnx::Sub(%1409, %1412)\n",
      "  %1414 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1413)\n",
      "  %1415 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1416 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1414, %1415)\n",
      "  %1417 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1416)\n",
      "  %1418 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1419 : Float(1, 196, 1, device=cpu) = onnx::Add(%1417, %1418)\n",
      "  %1420 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1419)\n",
      "  %1421 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1413, %1420)\n",
      "  %1422 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1421, %layers.2.blocks.2.norm1.weight)\n",
      "  %1423 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1422, %layers.2.blocks.2.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1431 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1423, %2851) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %1445 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1431, %2858) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %1446 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1445) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1455 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1446, %2863) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1462 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1455, %2867) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %1467 : Float(4, 49, 1152, strides=[56448, 1152, 1], device=cpu) = onnx::MatMul(%1462, %2868)\n",
      "  %1468 : Float(4, 49, 1152, strides=[56448, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.2.attn.qkv.bias, %1467) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1478 : Float(4, 49, 3, 12, 32, strides=[56448, 1152, 384, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1468, %2874) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1479 : Float(3, 4, 12, 49, 32, strides=[384, 56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%1478) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1480 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1481 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1479, %1480) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1482 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1483 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1479, %1482) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1484 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1485 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1479, %1484) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1486 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %1487 : Float(4, 12, 49, 32, strides=[18816, 32, 384, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1481, %1486)\n",
      "  %1488 : Float(4, 12, 32, 49, strides=[56448, 32, 1, 1152], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%1483) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1489 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1487, %1488) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1497 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1489, %2879) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %1498 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%1497) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1499 : Float(4, 12, 49, 32, strides=[18816, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1498, %1485) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1500 : Float(4, 49, 12, 32, strides=[18816, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%1499) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1505 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1500, %2883) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1507 : Float(4, 49, 384, strides=[18816, 384, 1], device=cpu) = onnx::MatMul(%1505, %2884)\n",
      "  %1508 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.2.attn.proj.bias, %1507) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1517 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1508, %2889) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %1518 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  2  2  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %1519 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1517, %1518) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %1520 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1519) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1521 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  14  14  -1 [ CPULongType{4} ]]()\n",
      "  %1522 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1520, %1521) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1528 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1522, %2893) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %1529 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1409, %1528) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %1530 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1529)\n",
      "  %1531 : Float(1, 196, 384) = onnx::Sub(%1529, %1530)\n",
      "  %1532 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1531)\n",
      "  %1533 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1534 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1532, %1533)\n",
      "  %1535 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1534)\n",
      "  %1536 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1537 : Float(1, 196, 1, device=cpu) = onnx::Add(%1535, %1536)\n",
      "  %1538 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1537)\n",
      "  %1539 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1531, %1538)\n",
      "  %1540 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1539, %layers.2.blocks.2.norm2.weight)\n",
      "  %1541 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1540, %layers.2.blocks.2.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1543 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::MatMul(%1541, %2894)\n",
      "  %1544 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.2.mlp.fc1.bias, %1543) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1545 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %1546 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Div(%1544, %1545)\n",
      "  %1547 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Erf(%1546)\n",
      "  %1548 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1549 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Add(%1547, %1548)\n",
      "  %1550 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Mul(%1544, %1549)\n",
      "  %1551 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %1552 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1550, %1551) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1554 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::MatMul(%1552, %2895)\n",
      "  %1555 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.2.mlp.fc2.bias, %1554) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1556 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1529, %1555) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %1559 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1556)\n",
      "  %1560 : Float(1, 196, 384) = onnx::Sub(%1556, %1559)\n",
      "  %1561 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1560)\n",
      "  %1562 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1563 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1561, %1562)\n",
      "  %1564 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1563)\n",
      "  %1565 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1566 : Float(1, 196, 1, device=cpu) = onnx::Add(%1564, %1565)\n",
      "  %1567 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1566)\n",
      "  %1568 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1560, %1567)\n",
      "  %1569 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1568, %layers.2.blocks.3.norm1.weight)\n",
      "  %1570 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1569, %layers.2.blocks.3.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1578 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1570, %2900) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %1579 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1580 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1581 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1582 : Float(1, 11, 14, 384, strides=[59136, 5376, 384, 1], device=cpu) = onnx::Slice(%1578, %1580, %1581, %1579)\n",
      "  %1583 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1584 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1586 : Float(1, 3, 14, 384, strides=[16128, 5376, 384, 1], device=cpu) = onnx::Slice(%1578, %1584, %1585, %1583)\n",
      "  %1587 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], device=cpu) = onnx::Concat[axis=1](%1582, %1586)\n",
      "  %1588 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1590 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1591 : Float(1, 14, 11, 384, strides=[59136, 4224, 384, 1], device=cpu) = onnx::Slice(%1587, %1589, %1590, %1588)\n",
      "  %1592 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1593 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1594 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1595 : Float(1, 14, 3, 384, strides=[16128, 1152, 384, 1], device=cpu) = onnx::Slice(%1587, %1593, %1594, %1592)\n",
      "  %1596 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%1591, %1595) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:260:0\n",
      "  %1610 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1596, %2907) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %1611 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1610) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1620 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1611, %2912) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1627 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1620, %2916) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %1632 : Float(4, 49, 1152, strides=[56448, 1152, 1], device=cpu) = onnx::MatMul(%1627, %2917)\n",
      "  %1633 : Float(4, 49, 1152, strides=[56448, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.3.attn.qkv.bias, %1632) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1643 : Float(4, 49, 3, 12, 32, strides=[56448, 1152, 384, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1633, %2923) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1644 : Float(3, 4, 12, 49, 32, strides=[384, 56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%1643) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1645 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1646 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1644, %1645) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1647 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1648 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1644, %1647) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1649 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1650 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1644, %1649) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1651 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %1652 : Float(4, 12, 49, 32, strides=[18816, 32, 384, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1646, %1651)\n",
      "  %1653 : Float(4, 12, 32, 49, strides=[56448, 32, 1, 1152], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%1648) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1654 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1652, %1653) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1662 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1654, %2928) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %1672 : Float(1, 4, 12, 49, 49, strides=[115248, 28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1662, %2934) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %1675 : Float(1, 4, 12, 49, 49, strides=[115248, 28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1672, %2936) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %1683 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1675, %2941) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:146:0\n",
      "  %1684 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%1683) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1685 : Float(4, 12, 49, 32, strides=[18816, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1684, %1650) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1686 : Float(4, 49, 12, 32, strides=[18816, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%1685) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1691 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1686, %2945) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1693 : Float(4, 49, 384, strides=[18816, 384, 1], device=cpu) = onnx::MatMul(%1691, %2946)\n",
      "  %1694 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.3.attn.proj.bias, %1693) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1703 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1694, %2951) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %1704 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  2  2  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %1705 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1703, %1704) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %1706 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1705) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1707 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  14  14  -1 [ CPULongType{4} ]]()\n",
      "  %1708 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1706, %1707) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1709 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1710 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %1711 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1712 : Float(1, 3, 14, 384, strides=[16128, 5376, 384, 1], device=cpu) = onnx::Slice(%1708, %1710, %1711, %1709)\n",
      "  %1713 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1714 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1715 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %1716 : Float(1, 11, 14, 384, strides=[59136, 5376, 384, 1], device=cpu) = onnx::Slice(%1708, %1714, %1715, %1713)\n",
      "  %1717 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], device=cpu) = onnx::Concat[axis=1](%1712, %1716)\n",
      "  %1718 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1719 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %1720 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1721 : Float(1, 14, 3, 384, strides=[16128, 1152, 384, 1], device=cpu) = onnx::Slice(%1717, %1719, %1720, %1718)\n",
      "  %1722 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1724 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %1725 : Float(1, 14, 11, 384, strides=[59136, 4224, 384, 1], device=cpu) = onnx::Slice(%1717, %1723, %1724, %1722)\n",
      "  %1726 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%1721, %1725) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:282:0\n",
      "  %1732 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1726, %2955) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %1733 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1556, %1732) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %1734 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1733)\n",
      "  %1735 : Float(1, 196, 384) = onnx::Sub(%1733, %1734)\n",
      "  %1736 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1735)\n",
      "  %1737 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1738 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1736, %1737)\n",
      "  %1739 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1738)\n",
      "  %1740 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1741 : Float(1, 196, 1, device=cpu) = onnx::Add(%1739, %1740)\n",
      "  %1742 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1741)\n",
      "  %1743 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1735, %1742)\n",
      "  %1744 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1743, %layers.2.blocks.3.norm2.weight)\n",
      "  %1745 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1744, %layers.2.blocks.3.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1747 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::MatMul(%1745, %2956)\n",
      "  %1748 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.3.mlp.fc1.bias, %1747) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1749 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %1750 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Div(%1748, %1749)\n",
      "  %1751 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Erf(%1750)\n",
      "  %1752 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1753 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Add(%1751, %1752)\n",
      "  %1754 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Mul(%1748, %1753)\n",
      "  %1755 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %1756 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1754, %1755) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1758 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::MatMul(%1756, %2957)\n",
      "  %1759 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.3.mlp.fc2.bias, %1758) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1760 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1733, %1759) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %1763 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1760)\n",
      "  %1764 : Float(1, 196, 384) = onnx::Sub(%1760, %1763)\n",
      "  %1765 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1764)\n",
      "  %1766 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1767 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1765, %1766)\n",
      "  %1768 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1767)\n",
      "  %1769 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1770 : Float(1, 196, 1, device=cpu) = onnx::Add(%1768, %1769)\n",
      "  %1771 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1770)\n",
      "  %1772 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1764, %1771)\n",
      "  %1773 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1772, %layers.2.blocks.4.norm1.weight)\n",
      "  %1774 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1773, %layers.2.blocks.4.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1782 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1774, %2962) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %1796 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1782, %2969) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %1797 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1796) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1806 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1797, %2974) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1813 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1806, %2978) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %1818 : Float(4, 49, 1152, strides=[56448, 1152, 1], device=cpu) = onnx::MatMul(%1813, %2979)\n",
      "  %1819 : Float(4, 49, 1152, strides=[56448, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.4.attn.qkv.bias, %1818) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1829 : Float(4, 49, 3, 12, 32, strides=[56448, 1152, 384, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1819, %2985) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1830 : Float(3, 4, 12, 49, 32, strides=[384, 56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%1829) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1831 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1832 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1830, %1831) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1833 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1834 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1830, %1833) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1835 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1836 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1830, %1835) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1837 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %1838 : Float(4, 12, 49, 32, strides=[18816, 32, 384, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1832, %1837)\n",
      "  %1839 : Float(4, 12, 32, 49, strides=[56448, 32, 1, 1152], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%1834) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1840 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1838, %1839) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %1848 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1840, %2990) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %1849 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%1848) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1850 : Float(4, 12, 49, 32, strides=[18816, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%1849, %1836) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1851 : Float(4, 49, 12, 32, strides=[18816, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%1850) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1856 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1851, %2994) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %1858 : Float(4, 49, 384, strides=[18816, 384, 1], device=cpu) = onnx::MatMul(%1856, %2995)\n",
      "  %1859 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.4.attn.proj.bias, %1858) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1868 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1859, %3000) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %1869 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  2  2  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %1870 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1868, %1869) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %1871 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1870) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1872 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  14  14  -1 [ CPULongType{4} ]]()\n",
      "  %1873 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1871, %1872) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %1879 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1873, %3004) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %1880 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1760, %1879) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %1881 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1880)\n",
      "  %1882 : Float(1, 196, 384) = onnx::Sub(%1880, %1881)\n",
      "  %1883 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1882)\n",
      "  %1884 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1885 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1883, %1884)\n",
      "  %1886 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1885)\n",
      "  %1887 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1888 : Float(1, 196, 1, device=cpu) = onnx::Add(%1886, %1887)\n",
      "  %1889 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1888)\n",
      "  %1890 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1882, %1889)\n",
      "  %1891 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1890, %layers.2.blocks.4.norm2.weight)\n",
      "  %1892 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1891, %layers.2.blocks.4.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1894 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::MatMul(%1892, %3005)\n",
      "  %1895 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.4.mlp.fc1.bias, %1894) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1896 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %1897 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Div(%1895, %1896)\n",
      "  %1898 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Erf(%1897)\n",
      "  %1899 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1900 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Add(%1898, %1899)\n",
      "  %1901 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Mul(%1895, %1900)\n",
      "  %1902 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %1903 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1901, %1902) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1905 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::MatMul(%1903, %3006)\n",
      "  %1906 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.4.mlp.fc2.bias, %1905) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %1907 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1880, %1906) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %1910 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1907)\n",
      "  %1911 : Float(1, 196, 384) = onnx::Sub(%1907, %1910)\n",
      "  %1912 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%1911)\n",
      "  %1913 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1914 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%1912, %1913)\n",
      "  %1915 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%1914)\n",
      "  %1916 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %1917 : Float(1, 196, 1, device=cpu) = onnx::Add(%1915, %1916)\n",
      "  %1918 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%1917)\n",
      "  %1919 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%1911, %1918)\n",
      "  %1920 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%1919, %layers.2.blocks.5.norm1.weight)\n",
      "  %1921 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1920, %layers.2.blocks.5.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %1929 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1921, %3011) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %1930 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1931 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1932 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1933 : Float(1, 11, 14, 384, strides=[59136, 5376, 384, 1], device=cpu) = onnx::Slice(%1929, %1931, %1932, %1930)\n",
      "  %1934 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1935 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1936 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1937 : Float(1, 3, 14, 384, strides=[16128, 5376, 384, 1], device=cpu) = onnx::Slice(%1929, %1935, %1936, %1934)\n",
      "  %1938 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], device=cpu) = onnx::Concat[axis=1](%1933, %1937)\n",
      "  %1939 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1940 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1941 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %1942 : Float(1, 14, 11, 384, strides=[59136, 4224, 384, 1], device=cpu) = onnx::Slice(%1938, %1940, %1941, %1939)\n",
      "  %1943 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %1944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1945 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}]()\n",
      "  %1946 : Float(1, 14, 3, 384, strides=[16128, 1152, 384, 1], device=cpu) = onnx::Slice(%1938, %1944, %1945, %1943)\n",
      "  %1947 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%1942, %1946) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:260:0\n",
      "  %1961 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1947, %3018) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %1962 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%1961) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1971 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1962, %3023) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %1978 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1971, %3027) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %1983 : Float(4, 49, 1152, strides=[56448, 1152, 1], device=cpu) = onnx::MatMul(%1978, %3028)\n",
      "  %1984 : Float(4, 49, 1152, strides=[56448, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.5.attn.qkv.bias, %1983) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %1994 : Float(4, 49, 3, 12, 32, strides=[56448, 1152, 384, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%1984, %3034) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1995 : Float(3, 4, 12, 49, 32, strides=[384, 56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%1994) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %1996 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %1997 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1995, %1996) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %1998 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %1999 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1995, %1998) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %2000 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2001 : Float(4, 12, 49, 32, strides=[56448, 32, 1152, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%1995, %2000) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %2002 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %2003 : Float(4, 12, 49, 32, strides=[18816, 32, 384, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1997, %2002)\n",
      "  %2004 : Float(4, 12, 32, 49, strides=[56448, 32, 1, 1152], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%1999) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %2005 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%2003, %2004) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %2013 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2005, %3039) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %2023 : Float(1, 4, 12, 49, 49, strides=[115248, 28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2013, %3045) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %2026 : Float(1, 4, 12, 49, 49, strides=[115248, 28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2023, %3047) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:145:0\n",
      "  %2034 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2026, %3052) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:146:0\n",
      "  %2035 : Float(4, 12, 49, 49, strides=[28812, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%2034) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2036 : Float(4, 12, 49, 32, strides=[18816, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%2035, %2001) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2037 : Float(4, 49, 12, 32, strides=[18816, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%2036) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2042 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2037, %3056) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2044 : Float(4, 49, 384, strides=[18816, 384, 1], device=cpu) = onnx::MatMul(%2042, %3057)\n",
      "  %2045 : Float(4, 49, 384, strides=[18816, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.5.attn.proj.bias, %2044) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2054 : Float(4, 7, 7, 384, strides=[18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2045, %3062) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %2055 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  2  2  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %2056 : Float(1, 2, 2, 7, 7, 384, strides=[75264, 37632, 18816, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2054, %2055) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %2057 : Float(1, 2, 7, 2, 7, 384, strides=[75264, 37632, 5376, 2688, 384, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%2056) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %2058 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=  1  14  14  -1 [ CPULongType{4} ]]()\n",
      "  %2059 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2057, %2058) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %2060 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2061 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %2062 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2063 : Float(1, 3, 14, 384, strides=[16128, 5376, 384, 1], device=cpu) = onnx::Slice(%2059, %2061, %2062, %2060)\n",
      "  %2064 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2065 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %2066 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %2067 : Float(1, 11, 14, 384, strides=[59136, 5376, 384, 1], device=cpu) = onnx::Slice(%2059, %2065, %2066, %2064)\n",
      "  %2068 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], device=cpu) = onnx::Concat[axis=1](%2063, %2067)\n",
      "  %2069 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2070 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %2071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2072 : Float(1, 14, 3, 384, strides=[16128, 1152, 384, 1], device=cpu) = onnx::Slice(%2068, %2070, %2071, %2069)\n",
      "  %2073 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2074 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %2075 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-3}]()\n",
      "  %2076 : Float(1, 14, 11, 384, strides=[59136, 4224, 384, 1], device=cpu) = onnx::Slice(%2068, %2074, %2075, %2073)\n",
      "  %2077 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=2](%2072, %2076) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:282:0\n",
      "  %2083 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2077, %3066) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %2084 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1907, %2083) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %2085 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%2084)\n",
      "  %2086 : Float(1, 196, 384) = onnx::Sub(%2084, %2085)\n",
      "  %2087 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Cast[to=1](%2086)\n",
      "  %2088 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2089 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Pow(%2087, %2088)\n",
      "  %2090 : Float(1, 196, device=cpu) = onnx::ReduceMean[axes=[-1]](%2089)\n",
      "  %2091 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %2092 : Float(1, 196, 1, device=cpu) = onnx::Add(%2090, %2091)\n",
      "  %2093 : Float(1, 196, 1, strides=[196, 1, 1], device=cpu) = onnx::Sqrt(%2092)\n",
      "  %2094 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Div(%2086, %2093)\n",
      "  %2095 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::Mul(%2094, %layers.2.blocks.5.norm2.weight)\n",
      "  %2096 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2095, %layers.2.blocks.5.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %2098 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::MatMul(%2096, %3067)\n",
      "  %2099 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.5.mlp.fc1.bias, %2098) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %2100 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %2101 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Div(%2099, %2100)\n",
      "  %2102 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Erf(%2101)\n",
      "  %2103 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2104 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Add(%2102, %2103)\n",
      "  %2105 : Float(1, 196, 1536, strides=[301056, 1536, 1], device=cpu) = onnx::Mul(%2099, %2104)\n",
      "  %2106 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %2107 : Float(1, 196, 1536, strides=[301056, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%2105, %2106) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2109 : Float(1, 196, 384, strides=[75264, 384, 1], device=cpu) = onnx::MatMul(%2107, %3068)\n",
      "  %2110 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.2.blocks.5.mlp.fc2.bias, %2109) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2111 : Float(1, 196, 384, strides=[75264, 384, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2084, %2110) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %2121 : Float(1, 14, 14, 384, strides=[75264, 5376, 384, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2111, %3073) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %2122 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2123 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %2124 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2125 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2126 : Float(1, 7, 14, 384, strides=[75264, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%2121, %2123, %2124, %2122, %2125) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:342:0\n",
      "  %2127 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2128 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %2129 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2130 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2131 : Float(1, 7, 7, 384, strides=[75264, 10752, 768, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%2126, %2128, %2129, %2127, %2130) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:342:0\n",
      "  %2132 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2133 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2134 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2135 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2136 : Float(1, 7, 14, 384, strides=[75264, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%2121, %2133, %2134, %2132, %2135) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:343:0\n",
      "  %2137 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2138 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %2139 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2140 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2141 : Float(1, 7, 7, 384, strides=[75264, 10752, 768, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%2136, %2138, %2139, %2137, %2140) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:343:0\n",
      "  %2142 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2143 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %2144 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2145 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2146 : Float(1, 7, 14, 384, strides=[75264, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%2121, %2143, %2144, %2142, %2145) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:344:0\n",
      "  %2147 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2148 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2149 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2151 : Float(1, 7, 7, 384, strides=[75264, 10752, 768, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%2146, %2148, %2149, %2147, %2150) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:344:0\n",
      "  %2152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2154 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2156 : Float(1, 7, 14, 384, strides=[75264, 10752, 384, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%2121, %2153, %2154, %2152, %2155) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %2157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2158 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %2160 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2161 : Float(1, 7, 7, 384, strides=[75264, 10752, 768, 1], requires_grad=1, device=cuda:0) = onnx::Slice(%2156, %2158, %2159, %2157, %2160) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:345:0\n",
      "  %2162 : Float(1, 7, 7, 1536, strides=[75264, 10752, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=-1](%2131, %2141, %2151, %2161) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:346:0\n",
      "  %2169 : Float(1, 49, 1536, strides=[75264, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2162, %3077) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:347:0\n",
      "  %2170 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2169)\n",
      "  %2171 : Float(1, 49, 1536) = onnx::Sub(%2169, %2170)\n",
      "  %2172 : Float(1, 49, 1536, strides=[75264, 1536, 1], device=cpu) = onnx::Cast[to=1](%2171)\n",
      "  %2173 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2174 : Float(1, 49, 1536, strides=[75264, 1536, 1], device=cpu) = onnx::Pow(%2172, %2173)\n",
      "  %2175 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2174)\n",
      "  %2176 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %2177 : Float(1, 49, 1, device=cpu) = onnx::Add(%2175, %2176)\n",
      "  %2178 : Float(1, 49, 1, strides=[49, 1, 1], device=cpu) = onnx::Sqrt(%2177)\n",
      "  %2179 : Float(1, 49, 1536, strides=[75264, 1536, 1], device=cpu) = onnx::Div(%2171, %2178)\n",
      "  %2180 : Float(1, 49, 1536, strides=[75264, 1536, 1], device=cpu) = onnx::Mul(%2179, %layers.2.downsample.norm.weight)\n",
      "  %2181 : Float(1, 49, 1536, strides=[75264, 1536, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2180, %layers.2.downsample.norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %2183 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%2181, %3078) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %2186 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2183)\n",
      "  %2187 : Float(1, 49, 768) = onnx::Sub(%2183, %2186)\n",
      "  %2188 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Cast[to=1](%2187)\n",
      "  %2189 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2190 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Pow(%2188, %2189)\n",
      "  %2191 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2190)\n",
      "  %2192 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %2193 : Float(1, 49, 1, device=cpu) = onnx::Add(%2191, %2192)\n",
      "  %2194 : Float(1, 49, 1, strides=[49, 1, 1], device=cpu) = onnx::Sqrt(%2193)\n",
      "  %2195 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Div(%2187, %2194)\n",
      "  %2196 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Mul(%2195, %layers.3.blocks.0.norm1.weight)\n",
      "  %2197 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2196, %layers.3.blocks.0.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %2205 : Float(1, 7, 7, 768, strides=[37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2197, %3083) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %2219 : Float(1, 1, 7, 1, 7, 768, strides=[37632, 37632, 5376, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2205, %3090) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %2220 : Float(1, 1, 1, 7, 7, 768, strides=[37632, 37632, 5376, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%2219) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %2229 : Float(1, 7, 7, 768, strides=[37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2220, %3095) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %2236 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2229, %3099) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %2241 : Float(1, 49, 2304, strides=[112896, 2304, 1], device=cpu) = onnx::MatMul(%2236, %3100)\n",
      "  %2242 : Float(1, 49, 2304, strides=[112896, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.3.blocks.0.attn.qkv.bias, %2241) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %2252 : Float(1, 49, 3, 24, 32, strides=[112896, 2304, 768, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2242, %3106) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %2253 : Float(3, 1, 24, 49, 32, strides=[768, 112896, 32, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%2252) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %2254 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %2255 : Float(1, 24, 49, 32, strides=[112896, 32, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%2253, %2254) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %2256 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2257 : Float(1, 24, 49, 32, strides=[112896, 32, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%2253, %2256) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %2258 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2259 : Float(1, 24, 49, 32, strides=[112896, 32, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%2253, %2258) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %2260 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %2261 : Float(1, 24, 49, 32, strides=[37632, 32, 768, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%2255, %2260)\n",
      "  %2262 : Float(1, 24, 32, 49, strides=[112896, 32, 1, 2304], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%2257) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %2263 : Float(1, 24, 49, 49, strides=[57624, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%2261, %2262) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %2271 : Float(1, 24, 49, 49, strides=[57624, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2263, %3111) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %2272 : Float(1, 24, 49, 49, strides=[57624, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%2271) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2273 : Float(1, 24, 49, 32, strides=[37632, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%2272, %2259) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2274 : Float(1, 49, 24, 32, strides=[37632, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%2273) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2279 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2274, %3115) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2281 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::MatMul(%2279, %3116)\n",
      "  %2282 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.3.blocks.0.attn.proj.bias, %2281) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2291 : Float(1, 7, 7, 768, strides=[37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2282, %3121) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %2292 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %2293 : Float(1, 1, 1, 7, 7, 768, strides=[37632, 37632, 37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2291, %2292) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %2294 : Float(1, 1, 7, 1, 7, 768, strides=[37632, 37632, 5376, 37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%2293) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %2295 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  7  7 -1 [ CPULongType{4} ]]()\n",
      "  %2296 : Float(1, 7, 7, 768, strides=[37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2294, %2295) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %2302 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2296, %3125) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %2303 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2183, %2302) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %2304 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2303)\n",
      "  %2305 : Float(1, 49, 768) = onnx::Sub(%2303, %2304)\n",
      "  %2306 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Cast[to=1](%2305)\n",
      "  %2307 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2308 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Pow(%2306, %2307)\n",
      "  %2309 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2308)\n",
      "  %2310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %2311 : Float(1, 49, 1, device=cpu) = onnx::Add(%2309, %2310)\n",
      "  %2312 : Float(1, 49, 1, strides=[49, 1, 1], device=cpu) = onnx::Sqrt(%2311)\n",
      "  %2313 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Div(%2305, %2312)\n",
      "  %2314 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Mul(%2313, %layers.3.blocks.0.norm2.weight)\n",
      "  %2315 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2314, %layers.3.blocks.0.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %2317 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::MatMul(%2315, %3126)\n",
      "  %2318 : Float(1, 49, 3072, strides=[150528, 3072, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.3.blocks.0.mlp.fc1.bias, %2317) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %2319 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %2320 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::Div(%2318, %2319)\n",
      "  %2321 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::Erf(%2320)\n",
      "  %2322 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2323 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::Add(%2321, %2322)\n",
      "  %2324 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::Mul(%2318, %2323)\n",
      "  %2325 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %2326 : Float(1, 49, 3072, strides=[150528, 3072, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%2324, %2325) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2328 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::MatMul(%2326, %3127)\n",
      "  %2329 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.3.blocks.0.mlp.fc2.bias, %2328) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2330 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2303, %2329) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %2333 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2330)\n",
      "  %2334 : Float(1, 49, 768) = onnx::Sub(%2330, %2333)\n",
      "  %2335 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Cast[to=1](%2334)\n",
      "  %2336 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2337 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Pow(%2335, %2336)\n",
      "  %2338 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2337)\n",
      "  %2339 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %2340 : Float(1, 49, 1, device=cpu) = onnx::Add(%2338, %2339)\n",
      "  %2341 : Float(1, 49, 1, strides=[49, 1, 1], device=cpu) = onnx::Sqrt(%2340)\n",
      "  %2342 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Div(%2334, %2341)\n",
      "  %2343 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Mul(%2342, %layers.3.blocks.1.norm1.weight)\n",
      "  %2344 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2343, %layers.3.blocks.1.norm1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %2352 : Float(1, 7, 7, 768, strides=[37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2344, %3132) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:255:0\n",
      "  %2366 : Float(1, 1, 7, 1, 7, 768, strides=[37632, 37632, 5376, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2352, %3139) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:55:0\n",
      "  %2367 : Float(1, 1, 1, 7, 7, 768, strides=[37632, 37632, 5376, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%2366) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %2376 : Float(1, 7, 7, 768, strides=[37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2367, %3144) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:56:0\n",
      "  %2383 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2376, %3148) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:270:0\n",
      "  %2388 : Float(1, 49, 2304, strides=[112896, 2304, 1], device=cpu) = onnx::MatMul(%2383, %3149)\n",
      "  %2389 : Float(1, 49, 2304, strides=[112896, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.3.blocks.1.attn.qkv.bias, %2388) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %2399 : Float(1, 49, 3, 24, 32, strides=[112896, 2304, 768, 32, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2389, %3155) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %2400 : Float(3, 1, 24, 49, 32, strides=[768, 112896, 32, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[2, 0, 3, 1, 4]](%2399) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:132:0\n",
      "  %2401 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %2402 : Float(1, 24, 49, 32, strides=[112896, 32, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%2400, %2401) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %2403 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2404 : Float(1, 24, 49, 32, strides=[112896, 32, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%2400, %2403) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %2405 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2406 : Float(1, 24, 49, 32, strides=[112896, 32, 2304, 1], requires_grad=1, device=cuda:0) = onnx::Gather[axis=0](%2400, %2405) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:133:0\n",
      "  %2407 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %2408 : Float(1, 24, 49, 32, strides=[37632, 32, 768, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%2402, %2407)\n",
      "  %2409 : Float(1, 24, 32, 49, strides=[112896, 32, 1, 2304], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2]](%2404) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %2410 : Float(1, 24, 49, 49, strides=[57624, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%2408, %2409) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:136:0\n",
      "  %2418 : Float(1, 24, 49, 49, strides=[57624, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2410, %3160) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:141:0\n",
      "  %2419 : Float(1, 24, 49, 49, strides=[57624, 2401, 49, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=3](%2418) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2420 : Float(1, 24, 49, 32, strides=[37632, 1568, 32, 1], requires_grad=1, device=cuda:0) = onnx::MatMul(%2419, %2406) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2421 : Float(1, 49, 24, 32, strides=[37632, 32, 1568, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1, 3]](%2420) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2426 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2421, %3164) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:153:0\n",
      "  %2428 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::MatMul(%2426, %3165)\n",
      "  %2429 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.3.blocks.1.attn.proj.bias, %2428) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2438 : Float(1, 7, 7, 768, strides=[37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2429, %3170) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:276:0\n",
      "  %2439 : Long(6, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1  7  7 -1 [ CPULongType{6} ]]()\n",
      "  %2440 : Float(1, 1, 1, 7, 7, 768, strides=[37632, 37632, 37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2438, %2439) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:72:0\n",
      "  %2441 : Float(1, 1, 7, 1, 7, 768, strides=[37632, 37632, 5376, 37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5]](%2440) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %2442 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  7  7 -1 [ CPULongType{4} ]]()\n",
      "  %2443 : Float(1, 7, 7, 768, strides=[37632, 5376, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2441, %2442) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:73:0\n",
      "  %2449 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%2443, %3174) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:288:0\n",
      "  %2450 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2330, %2449) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:289:0\n",
      "  %2451 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2450)\n",
      "  %2452 : Float(1, 49, 768) = onnx::Sub(%2450, %2451)\n",
      "  %2453 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Cast[to=1](%2452)\n",
      "  %2454 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2455 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Pow(%2453, %2454)\n",
      "  %2456 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2455)\n",
      "  %2457 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %2458 : Float(1, 49, 1, device=cpu) = onnx::Add(%2456, %2457)\n",
      "  %2459 : Float(1, 49, 1, strides=[49, 1, 1], device=cpu) = onnx::Sqrt(%2458)\n",
      "  %2460 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Div(%2452, %2459)\n",
      "  %2461 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Mul(%2460, %layers.3.blocks.1.norm2.weight)\n",
      "  %2462 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2461, %layers.3.blocks.1.norm2.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %2464 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::MatMul(%2462, %3175)\n",
      "  %2465 : Float(1, 49, 3072, strides=[150528, 3072, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.3.blocks.1.mlp.fc1.bias, %2464) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %2466 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %2467 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::Div(%2465, %2466)\n",
      "  %2468 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::Erf(%2467)\n",
      "  %2469 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2470 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::Add(%2468, %2469)\n",
      "  %2471 : Float(1, 49, 3072, strides=[150528, 3072, 1], device=cpu) = onnx::Mul(%2465, %2470)\n",
      "  %2472 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %2473 : Float(1, 49, 3072, strides=[150528, 3072, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%2471, %2472) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2475 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::MatMul(%2473, %3176)\n",
      "  %2476 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%layers.3.blocks.1.mlp.fc2.bias, %2475) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1169:0\n",
      "  %2477 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2450, %2476) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:292:0\n",
      "  %2478 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2477)\n",
      "  %2479 : Float(1, 49, 768) = onnx::Sub(%2477, %2478)\n",
      "  %2480 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Cast[to=1](%2479)\n",
      "  %2481 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %2482 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Pow(%2480, %2481)\n",
      "  %2483 : Float(1, 49, device=cpu) = onnx::ReduceMean[axes=[-1]](%2482)\n",
      "  %2484 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "  %2485 : Float(1, 49, 1, device=cpu) = onnx::Add(%2483, %2484)\n",
      "  %2486 : Float(1, 49, 1, strides=[49, 1, 1], device=cpu) = onnx::Sqrt(%2485)\n",
      "  %2487 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Div(%2479, %2486)\n",
      "  %2488 : Float(1, 49, 768, strides=[37632, 768, 1], device=cpu) = onnx::Mul(%2487, %norm.weight)\n",
      "  %2489 : Float(1, 49, 768, strides=[37632, 768, 1], requires_grad=1, device=cuda:0) = onnx::Add(%2488, %norm.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2347:0\n",
      "  %2490 : Float(1, 768, 49, strides=[37632, 1, 768], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1]](%2489) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:598:0\n",
      "  %2491 : Float(1, 768, 1, strides=[768, 1, 768], requires_grad=1, device=cuda:0) = onnx::GlobalAveragePool(%2490) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/pooling.py:1128:0\n",
      "  %2492 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cuda:0) = onnx::Flatten[axis=1](%2491) # /workspace/sdd_sony/Pytorch/Swin_Transformer/models/swin_transformer.py:599:0\n",
      "  %output : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%2492, %head.weight, %head.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, x, \"Swin_T_window_process.onnx\", verbose=True, opset_version=11, export_params=True, input_names = ['input'], output_names = ['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2850e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import shape_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abc4a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = r'Swin_T.onnx'\n",
    "onnx.save(onnx.shape_inference.infer_shapes(onnx.load(model)), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779116c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load ('transfusion_head_sim.onnx')\n",
    "onnx.checker.check_model(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921b38d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading engine from file transfusion_head.engine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "logger = trt.Logger(trt.Logger.WARNING)\n",
    "runtime = trt.Runtime(logger)\n",
    "trt.init_libnvinfer_plugins(logger, \"\")\n",
    "engine_file = \"transfusion_head.engine\"\n",
    "assert os.path.exists(engine_file)\n",
    "print(\"Reading engine from file {}\".format(engine_file))\n",
    "with open(engine_file, \"rb\") as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b451e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorrt.tensorrt.ICudaEngine object at 0x7efc501d7c00>\n"
     ]
    }
   ],
   "source": [
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2358a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be17ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = trt.Logger(trt.Logger.WARNING)\n",
    "builder = trt.Builder(logger)\n",
    "trt.init_libnvinfer_plugins(logger, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c61769",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e460a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser for onnx model\n",
    "parser = trt.OnnxParser(network, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc89aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INT64 to INT32\n",
    "# ! python -m onnxsim Swin_T.onnx Swin_T32.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c3b5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model_path = r'trans_modified1.onnx'\n",
    "success = parser.parse_from_file(model_path)\n",
    "for idx in range(parser.num_errors):\n",
    "    print(parser.get_error(idx))\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ec7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = builder.create_builder_config()\n",
    "# config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 20) # 1 MiB\n",
    "serialized_engine = builder.build_serialized_network(network, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa08914",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transfusion_head.engine\", \"wb\") as f:\n",
    "    f.write(serialized_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba94f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "runtime = trt.Runtime(logger)\n",
    "engine = runtime.deserialize_cuda_engine(serialized_engine)\n",
    "# context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecff490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For transfusion_head\n",
    "def infer_metas(engine, input_file):\n",
    "\n",
    "    with engine.create_execution_context() as context:\n",
    "        # Set input shape based on image dimensions for inference\n",
    "        # context.set_binding_shape(engine.get_binding_index(\"input\"), (1, 512, 180, 180))\n",
    "        # Allocate host and device buffers\n",
    "        bindings = []\n",
    "        outputs_host = []\n",
    "        outputs_device = []\n",
    "        output_size = 0\n",
    "        for binding in engine:\n",
    "            binding_idx = engine.get_binding_index(binding)\n",
    "            size = trt.volume(context.get_binding_shape(binding_idx))\n",
    "            dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "            if engine.binding_is_input(binding):\n",
    "                input_buffer = np.ascontiguousarray(input_file)\n",
    "                input_memory = cuda.mem_alloc(input_buffer.nbytes) # I made one change\n",
    "                bindings.append(int(input_memory))\n",
    "                print(\"input:\",binding,binding_idx,size,dtype)\n",
    "            else:\n",
    "                output_size = output_size + size\n",
    "                output_buffer = cuda.pagelocked_empty(size, dtype) # Host mem\n",
    "                output_memory = cuda.mem_alloc(output_buffer.nbytes) # Device mem\n",
    "                bindings.append(int(output_memory))\n",
    "                outputs_host.append(output_buffer)\n",
    "                outputs_device.append(output_memory)\n",
    "                print(\"output:\",binding,binding_idx,size,dtype)\n",
    "        time_trt = []\n",
    "        total_trt = 0\n",
    "        for i in range (0, 100):\n",
    "            stream = cuda.Stream()\n",
    "            start_t = time.time()\n",
    "            # Transfer input data to the GPU.\n",
    "            cuda.memcpy_htod_async(input_memory, input_buffer, stream)\n",
    "            # Run inference\n",
    "            context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "            # Transfer prediction output from the GPU.\n",
    "            for j in range(0, len(outputs_device)):\n",
    "                cuda.memcpy_dtoh_async(outputs_host[j], outputs_device[j], stream)\n",
    "            # Synchronize the stream\n",
    "            stream.synchronize()\n",
    "            end_t = time.time()\n",
    "            time_trt.append(end_t - start_t)\n",
    "            total_trt += time_trt[i]\n",
    "        print(time_trt[:10])\n",
    "        print(\"average time cost:\", total_trt * 10, \"ms\")\n",
    "\n",
    "    return outputs_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "653a0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Swin_T\n",
    "def infer_image(engine, input_file):\n",
    "    # print(\"Reading input image from file {}\".format(input_file))\n",
    "    with Image.open(input_file) as img:\n",
    "        img = img.resize((224,224)) # for specific model\n",
    "        input_image = preprocess(img)\n",
    "        image_width = img.width\n",
    "        image_height = img.height\n",
    "\n",
    "    with engine.create_execution_context() as context:\n",
    "        # Set input shape based on image dimensions for inference\n",
    "        context.set_binding_shape(engine.get_binding_index(\"input\"), (1, 3, image_height, image_width))\n",
    "        # Allocate host and device buffers\n",
    "        bindings = []\n",
    "        for binding in engine:\n",
    "            binding_idx = engine.get_binding_index(binding)\n",
    "            size = trt.volume(context.get_binding_shape(binding_idx))\n",
    "            dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "            if engine.binding_is_input(binding):\n",
    "                input_buffer = np.ascontiguousarray(input_image)\n",
    "                input_memory = cuda.mem_alloc(input_buffer.nbytes) # I made one change\n",
    "                bindings.append(int(input_memory))\n",
    "            else:\n",
    "                output_buffer = cuda.pagelocked_empty(size, dtype)\n",
    "                output_memory = cuda.mem_alloc(output_buffer.nbytes)\n",
    "                bindings.append(int(output_memory))\n",
    "        time_trt = []\n",
    "        total_trt = 0\n",
    "        for i in range (0, 100):\n",
    "            stream = cuda.Stream()\n",
    "            start_t = time.time()\n",
    "            # Transfer input data to the GPU.\n",
    "            cuda.memcpy_htod_async(input_memory, input_buffer, stream)\n",
    "            # Run inference\n",
    "            context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "            # Transfer prediction output from the GPU.\n",
    "            cuda.memcpy_dtoh_async(output_buffer, output_memory, stream)\n",
    "            # Synchronize the stream\n",
    "            stream.synchronize()\n",
    "            end_t = time.time()\n",
    "            time_trt.append(end_t - start_t)\n",
    "            total_trt += time_trt[i]\n",
    "        print(time_trt[:10])\n",
    "        print(\"average time cost:\", total_trt * 10, \"ms\")\n",
    "\n",
    "    return output_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6ea6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    # Mean normalization\n",
    "    # mean = np.array([0.485, 0.456, 0.406]).astype('float32')\n",
    "    # stddev = np.array([0.229, 0.224, 0.225]).astype('float32')\n",
    "    # data = (np.asarray(image).astype('float32') / float(255.0) - mean) / stddev\n",
    "    # Switch from HWC to to CHW order\n",
    "    # return np.moveaxis(data, 2, 0)\n",
    "    data = np.asarray(image).astype('float32') / float(255.0)\n",
    "    return np.moveaxis(data, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0156b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: input.1 0 16588800 <class 'numpy.float32'>\n",
      "output: 125 1 324000 <class 'numpy.float32'>\n",
      "output: topk_values 2 200 <class 'numpy.float32'>\n",
      "output: topk_indices 3 200 <class 'numpy.int32'>\n",
      "output: 609 4 2000 <class 'numpy.float32'>\n",
      "output: 611 5 200 <class 'numpy.float32'>\n",
      "output: 612 6 600 <class 'numpy.float32'>\n",
      "output: 613 7 400 <class 'numpy.float32'>\n",
      "output: 614 8 400 <class 'numpy.float32'>\n",
      "output: 615 9 2000 <class 'numpy.float32'>\n",
      "output: 610 10 400 <class 'numpy.float32'>\n",
      "[0.03230023384094238, 0.01703643798828125, 0.016898632049560547, 0.016889333724975586, 0.016976356506347656, 0.017724990844726562, 0.015923261642456055, 0.015676498413085938, 0.01564168930053711, 0.015628576278686523]\n",
      "average time cost: 15.53398609161377 ms\n"
     ]
    }
   ],
   "source": [
    "# For transfusion_head\n",
    "import torch\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "\n",
    "head_metas = torch.load('head_metas.pt').cpu()\n",
    "input_metas = head_metas.detach().numpy()\n",
    "\n",
    "result = infer_metas(engine, input_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b47da5e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.543236   10.544364   20.53587    57.429466   18.672396   11.646322\n",
      "  86.39738    91.4855    132.5144    103.54572    12.630223   49.724945\n",
      "  76.37881   101.85127    19.493378   47.50386    17.174152   11.054919\n",
      "  12.364813   57.440735   14.474374  101.55739    18.84857    19.750654\n",
      "  13.233294   64.56557    16.256239    9.51982    28.65275    58.681667\n",
      "  11.377809    5.400988   53.325916    9.658897  110.23586    16.266914\n",
      "  34.553005   70.85452     7.2172832  47.63442    16.366432   69.47062\n",
      "  81.29295    16.168997    7.05346   102.21612    59.183125   81.309135\n",
      "  47.50633    20.369265    9.305943    9.538515   20.281738   22.476185\n",
      "  81.36619    55.221233   17.846592   13.830679   46.708023   86.40784\n",
      "  83.21894    21.514078  101.49793   119.324814   69.65016   100.56707\n",
      "  21.964771   19.330362   18.678183   12.205064   61.712975   13.711173\n",
      "  75.261696   55.657      52.559494   12.064835   19.525867  100.85688\n",
      "  47.435055  101.71742    50.305893   61.14659     6.445466   61.764843\n",
      "  66.73999    86.75011    61.0392    108.94675    46.794575   12.720647\n",
      "  15.57328    49.342827   30.111704   46.489655   69.85562     9.793102\n",
      "  56.472054   60.323845   22.18717    50.21684    66.16898    99.78041\n",
      "   8.750837   69.85415    47.23926    20.59502    12.8738     64.77044\n",
      "  66.15716    10.33063    11.806979   55.83055    39.117332   54.55763\n",
      "  47.201416   34.067654   14.594003   50.20351    19.26706    56.950104\n",
      "  12.401325   11.081476   56.54665    17.95147   101.3249     52.484364\n",
      "  56.454082  104.387794  111.77754    40.035355   13.149717    5.2790947\n",
      "  18.067366    4.736869   56.517776   19.310339   55.120018   10.182004\n",
      " 115.3178     29.695715   31.034306   48.895298   11.368779  102.61352\n",
      "  44.251667   69.67018    66.29444    50.32734    33.751274  119.310844\n",
      "  99.54584    12.675775   58.688225    7.3230104  83.59658    48.318203\n",
      "  14.634605   47.28017   112.54079    20.5948     27.765259   49.633484\n",
      " 101.49401   130.64354    25.059057   45.182755   56.484207   14.506414\n",
      "  54.300117   66.15333    51.393837  109.788025    8.858688   70.58926\n",
      "  99.734314    3.3540728  14.843609  111.83297    51.932648  132.95758\n",
      " 103.08725   114.1213     13.640216   14.480385    9.623263   16.469206\n",
      "  55.830555   62.760773   16.277767   65.94541   103.10614    98.96196\n",
      "  15.113302    4.518963   50.384453   23.396626   22.21701    47.112537\n",
      "  53.02568    22.69413    65.19268   142.6739     64.76111    68.780716\n",
      "  65.442024  142.68225   179.33745   165.11693    35.670593   90.440674\n",
      " 143.1553    129.48053   136.79828   123.79483    65.020256   38.722775\n",
      "  63.810432  132.64073   133.36325   139.5776    143.42036   140.60414\n",
      "  62.53409    64.47825   142.61855   156.13857    63.052948  142.64076\n",
      " 123.94677   140.43605   135.44376   142.4838     68.18311   137.32399\n",
      "  90.31335    62.80345   167.12906    85.866844  168.17601   171.80746\n",
      "  24.282238  147.21584    14.591613   64.19096   166.47112   141.31224\n",
      " 140.38736    14.58261   172.24625    64.99504   142.56091   166.56496\n",
      "  63.707863   36.04889    14.5950165  68.666756   64.01354   133.34016\n",
      "  38.04685   179.34833   178.62822    35.142372  125.269485  172.33345\n",
      " 141.70706   142.32909    54.433952   64.04907    65.46563   142.89265\n",
      "  63.935543   23.624454  137.87756   140.3124    140.112     145.38931\n",
      "  65.200356  125.47344   130.74303   124.48377   139.50882   157.77931\n",
      " 169.49289    64.01989   133.20676   178.79643   159.41827    90.07414\n",
      " 129.58795   141.4607     34.32006   123.63861   167.2861    130.34798\n",
      "  84.90689   135.4768    138.43019    72.38305    71.4578    139.4873\n",
      "  76.388664  129.6789     22.289854   86.289024   37.498417   65.21104\n",
      " 140.6447     70.70943    76.25107   132.61365   136.57086   138.46198\n",
      " 124.452065   69.67772    38.206055  109.60808    16.250948  138.66466\n",
      "  64.10331    68.621666  137.21301   134.61525   140.25711    72.025444\n",
      " 127.456024  139.37886   138.4561    118.37655   168.34409   122.288895\n",
      "  61.012638  142.45784    61.26864   138.8478    140.28201    64.149345\n",
      " 141.00519    22.649261  169.78302   167.50423   125.751915  124.27063\n",
      " 151.43062   128.43665    63.81662   141.70427   166.66684   140.00598\n",
      " 167.1047    172.31998   142.66376   135.25543   140.34619   166.65361\n",
      " 142.83679    64.074585   64.12553    66.31276   167.6163     80.36563\n",
      " 127.18004   130.19402    10.979928   42.47656   168.43399   125.0643\n",
      " 138.41432    15.632567  138.65529   159.85071   127.239044  171.33966\n",
      " 167.75183    73.56005   129.62209   142.4009     64.71318    88.994804\n",
      " 139.18553    36.068123  130.18665   165.76674    53.380833  143.42288\n",
      " 134.3936     62.26736   138.48482   137.25916    64.50113    76.41649\n",
      " 122.89628   132.7941     32.575912  138.15633   139.48842   168.32104\n",
      "  71.41541    68.63198   141.87639    27.448532 ]\n"
     ]
    }
   ],
   "source": [
    "print(result[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "793f0f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8616974353790283, 0.003162860870361328, 0.0031516551971435547, 0.003155946731567383, 0.003153085708618164, 0.0031495094299316406, 0.0031239986419677734, 0.003117084503173828, 0.0031232833862304688, 0.003178119659423828]\n",
      "average time cost: 11.530485153198242 ms\n"
     ]
    }
   ],
   "source": [
    "# For Swin_T\n",
    "import numpy as np\n",
    "import os\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "input_file  = \"images/bulbul.jpg\"\n",
    "result = infer_image(engine, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdcf1f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d5fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
